%Started on 9th August 2006
%Aug: 11, 22, 23, 24, 25, 28, 29, 30, 31
%Sep:  1,  7,  8
% 2007
%Jan: 15, 16, 17, 22, 26, 29, 30
%Feb:  1,  2,  4,  5,  6,  7,  8,  9, 11, 21, 22
%Mar:  8,  9, 13, 15, 16, 17, 19, 20, 21, 22, 27, 28, 29, 30, 31
%Apr:  1,  2,  3, 16, 18
%May:  1

%
% Chapter: Interior point methods
%
\label{ch:Ipm}

Interior point methods are well-suited to solving very
large scale optimization problems. Their theory is well understood
and a number of survey papers, monographs and academic books are available
\cite{GondzioTerlaky,Gonzaga92,PotraWright00,
RoosTerlakyVial,Terlaky96,MWright92,ipm:Wright97}.

This chapter is devoted to the derivation and analysis of primal--dual
path-following interior point methods. 
We present the elements that are at the base of this successful class
of algorithms, concentrating on their theoretical properties and
attractive features.
We also introduce and analyse the concept of symmetric neighbourhood,
and its consequences for practical algorithms.


%
% Section
%
\section{Derivation of primal--dual methods}
\label{sec:Derivation}

Consider the following primal--dual pair of linear programming problems 
in standard form
%
\be \label{eq:PrimalDualPair}
  \begin{array}{crlp{2cm}crl}
     & \min        & c^T x     & &     & \max        & b^T y \\
 (P) & \mbox{s.t.} & Ax = b,   & & (D) & \mbox{s.t.} & A^T y + s = c, \\
     &             & x \geq 0; & &     &             & s \geq 0,
  \end{array}
\ee
%
where $A \in \R^{m \times n}$, $x, s, c \in \R^{n}$ 
and $y, b \in \R^{m}$, $m<n$. We assume, without loss of generality,
that $A$ has full row rank, as linearly dependent rows can be
removed without changing the solution set.
This implies that a feasible $s \ge 0$ determines in a unique
way the value of $y$.
In fact, the $y$ variables can be eliminated thus producing the
symmetric combined primal--dual form studied by Todd and Ye \cite{ToddYe90}.

We define the sets of primal feasible points and of
dual feasible points as
\[
\mathcal{P} = \{ x : Ax = b, \; x \ge 0 \}, \qquad
\mathcal{D} = \{ (y,s) : A^T y + s = c, \; s \ge 0 \},
\]
and using this notation, we can rewrite the primal--dual pair 
(\ref{eq:PrimalDualPair}) as
\[
\min \; c^T x, \;\;  x    \in \mathcal{P}; \qquad
\max \; b^T y, \;\; (y,s) \in \mathcal{D}.
\]

In the derivation of interior point methods we will concentrate on
two closely related sets: the set of primal interior points and
the set of dual interior points 
\[
\mathcal{P}^0 = \{ x \in \mathcal{P} : x > 0 \}, \qquad
\mathcal{D}^0 = \{ (y,s) \in \mathcal{D} : s > 0 \}.
\]

We introduce the notation
\[
  w = (x,y,s)
\]
to denote a primal--dual point, and
we consider the set of feasible primal--dual points 
and the set of primal--dual interior points
\[
  \mathcal{F} = \mathcal{P} \times \mathcal{D}, \qquad
  \mathcal{F}^0 = \{ w \in \mathcal{F} : (x,s) > 0 \}.
\]
A primal--dual point $w\in\mathcal{F}^0$ is said to be {\em strictly feasible}
for the primal--dual pair (\ref{eq:PrimalDualPair}).

We recall here some well-known results on the relationship between
problems $(P)$ and $(D)$.
These can be found in plenty of sources, for example 
\cite{lp:Chvatal,Schrijver86}.
Our presentation is inspired by 
\cite{GulerRoosTerlakyVial,Megiddo,ipm:Wright97}.

\begin{lemma}[Weak duality]
Let $w \in \mathcal{F}$. Then $c^Tx \ge b^Ty$.
\end{lemma}
%
\begin{proof}
Since $x \in \mathcal{P}$ and $(y,s) \in \mathcal{D}$, 
the following holds:
\[
  c^Tx - b^Ty = c^Tx - x^TA^Ty = x^T(c - A^T y) = x^Ts \ge 0. \qedhere
\]
\end{proof}

The weak duality property states that the primal and dual objective
values bound each other.
The difference $c^Tx - b^Ty$ is called the {\em duality gap}.
When the objectives in both problems achieve their respective bounds,
that is, when the duality gap is zero, the primal--dual solution has
to be optimal. This can be formalised
in the following lemma.

\begin{lemma}[Strong duality]  \label{th:StrongDuality}
A point $x \in \mathcal{P}$ is an optimal solution if and only if
there exists a pair $(y,s) \in \mathcal{D}$ such that $c^Tx = b^Ty$.
\end{lemma}

Problem $(P)$ has a solution if and only if $\mathcal{P} \ne \emptyset$;
if also $\mathcal{D} \ne \emptyset$, then both problems admit an
optimal solution $w^* = (x^*, y^*, s^*)$, and by Lemma~\ref{th:StrongDuality}
the objective function 
values of both problems coincide at that point. 
Otherwise, if one of the sets $\mathcal{P}$ or $\mathcal{D}$ is empty, 
then the other is either unbounded or empty as well. 
In such cases, an optimal
solution for problem (\ref{eq:PrimalDualPair}) does not exist.

Optimality conditions let us recognise that a solution has been
found. They also provide insight on the development of algorithms 
for finding a solution.
The Karush-Kuhn-Tucker (\KKT) conditions express first-order optimality 
conditions for the primal--dual pair (\ref{eq:PrimalDualPair}).
They can be written as
\be  \label{eq:KKT}
\begin{array}{rcl}
  Ax      &=& b \\
  A^Ty +s &=& c \\
  XSe     &=& 0 \\
  (x,s)   &\ge& 0,
\end{array}
\ee
where $X, S \in \R^{n\times n}$ are diagonal matrices with elements 
$x_i$ and $s_i$ respectively, and $e \in \R^n$ is a vector 
of ones. In other words, an optimal solution is characterised by 
primal feasibility, dual feasibility and complementarity.

Complementarity can be seen as a certificate for optimality 
in linear programming \cite{phd:Jansen,Schrijver86}.
For non-optimal feasible iterates, complementarity measures the distance of the
iterate to optimality:
\be  \label{eq:DualityComplementarityGap}
  c^Tx - b^T y = x^T s.
\ee
The quantity $x^T s$ is called the {\em complementarity gap}.
When it is driven to zero, then a feasible solution is also optimal. 
It should be noted that the equality between the duality gap and the
complementarity gap of equation (\ref{eq:DualityComplementarityGap})
holds only for a feasible point.

In what follows, we make the standard assumption for the development
of interior point methods that $\mathcal{P}^0 \ne \emptyset$ and 
$\mathcal{D}^0 \ne \emptyset$. This is also referred to as the
{\em interior point assumption}. 
The interior point assumption corresponds to assuming that 
the primal--dual optimal face is 
bounded (this is mentioned in \cite{GonzagaCardia04} and also
in \cite[Lemma~2.2]{GulerRoosTerlakyVial}).
Cases when this assumption does not hold can be considered by allowing
the algorithm to accept infeasible iterates 
(see Section~\ref{sec:InfeasibleMethods}).

%
%
\subsection{The barrier problem}
\label{sec:BarrierProblem}

Many algorithms used in mathematical programming can be interpreted 
as path-following. Here we restrict our attention to the path described 
by the use of a logarithmic barrier function in linear programming.
Given the linear program in standard form $(P)$,
it is possible to write the corresponding {\em barrier problem}:
\[
  (P_\mu) \quad \min\; c^Tx - \mu \displaystyle\sum_{i=1}^n \ln x_i,
          \quad x \in \mathcal{P}^0.
\]

Problem $(P_\mu)$ denotes a family of problems parametrised by the 
quantity $\mu>0$ (typically small), which is called the {\em barrier parameter}
in the interior point literature. 

The presence of the logarithmic barrier in the objective function
of $(P_\mu)$ forces the iterates 
to stay in the interior of the feasible region, as this term heavily penalises 
points that are too close to the boundary. However, the influence exerted
by the logarithmic barrier can be controlled through the penalty
parameter $\mu$.
The weight on the barrier regulates the distance from the iterates to 
the boundary: as $\mu$ tends to zero, problem $(P_\mu)$ resembles
problem $(P)$ more and more closely.
It is worth noting that such an approach is 
viable only if it is actually possible to find a point that 
strictly satisfies the constraints, that is, if $\mathcal{P}^0 \ne \emptyset$.
If the feasible domain $\mathcal{P}$ is bounded, 
then both $(P)$ and $(P_\mu)$ admit optimal solutions. 

The objective function of problem $(P_\mu)$
is a strictly convex function. 
Therefore, for a fixed $\mu$, the problem has at most one global minimum. 
The minimizer, if it exists, is completely characterised 
by the associated \KKT conditions:
\[
\begin{array}{rcc}
   Ax               & = &  b \\
  \mu X^{-1}e +A^Ty & = &  c \\
   x                & > &  0.
\end{array}
\]
By substituting $s = \mu X^{-1}e$, we obtain the
standard (primal--dual) formulation of the so called 
{\em perturbed \KKT conditions}:
\be \label{eq:PerturbedKKT}
\begin{array}{rcc}
   Ax       & = & b \\
   A^Ty + s & = & c \\
   XSe      & = & \mu e \\
   (x,s)    & > & 0.
\end{array}
\ee

\ignore{
The following lemma has been proved by Megiddo \cite{Megiddo}.
\begin{lemma}
Problem $(P_\mu)$ 
is either unbounded for every  $\mu>0$ or has a unique optimal 
solution for every $\mu>0$.
\end{lemma}
}

If the perturbed \KKT conditions (\ref{eq:PerturbedKKT}) have a solution for 
a particular $\hat \mu>0$, then it has solution for every $\mu>0$.
Therefore, system (\ref{eq:PerturbedKKT}) determines 
a unique continuous smooth curve 
$w(\mu) = (x(\mu),y(\mu),s(\mu))$ toward the optimal set as $\mu\to 0$. 
In interior-point 
terminology, this curve is called the {\em central path}.
The study of the primal--dual properties of the central path was pioneered by
Megiddo \cite{Megiddo} and Bayer and Lagarias \cite{BayerLagarias}.

%Moreover, if $A$ has full rank, then the value of $y$ is 
%uniquely determined by the value of $x$. Therefore, 
%system (\ref{eq:PerturbedKKT}) has a unique solution $(x(\mu),y(\mu))$.

Under the assumptions that for a particular $\mu > 0$ the point
$w(\mu)$ is primal and dual feasible, we can state
a similar result to the one expressed by 
(\ref{eq:DualityComplementarityGap}):
\[
  g(\mu) := c^Tx(\mu) - b^T y(\mu) = x(\mu)^T s(\mu).
\]
That is, the duality gap corresponds to the complementarity gap.
Hence reducing either of them is identical.
Moreover, as $XSe - \mu e = 0$ implies $x_is_i = \mu$, $i = 1, \ldots, n$, 
we have
\be  \label{eq:AverageComplementarity}
   s(\mu)^T x(\mu) = n\mu,
\ee
and for $\mu \to 0$, also $g(\mu) \to 0$.
This implies that $c^Tx(\mu)\to c^Tx^*$ and $b^Ty(\mu) \to b^Ty^*$ 
as $\mu\to 0$, so the objective function values for the perturbed
problem converge to those of the original problem.
Furthermore, the following, stronger result holds.
%
\begin{theorem}
\label{th:CentralPathConvergence}
Under the assumptions of primal feasibility, dual feasibility, and
full row rank of matrix $A$, then as $\mu \to 0$:
\[
   x(\mu) \to x^*, \quad (y(\mu),s(\mu)) \to (y^*, s^*).
\]
\end{theorem}

Theorem~\ref{th:CentralPathConvergence} states that, under standard
well-definedness conditions, the central path converges to 
the optimal solution of the problem (\ref{eq:PrimalDualPair}).
Therefore, the central path can be used as a guideline to
reach the optimal set.
Algorithms that rely on the central path for finding the solution
are called path-following. We will introduce them 
in Section~\ref{sec:PathFollowingAlgorithms}.

The solution reached by following the central path is 
characterised by {\em strict complementarity}. 
This is described in the following result.

\begin{theorem}[Strict complementarity]
If $(P)$ and $(D)$ are feasible, then there exist a point $x^* \in\mathcal{P}$
and a pair $(y^*,s^*) \in \mathcal{D}$ such that
\[
(x^*)^T s^* = 0 \quad\mbox{ and }\quad x^*_i + s_i^* >0, \quad i = 1,\ldots,n.
\]
\end{theorem}

A solution $(x^*,s^*)$ that satisfies the above theorem is said to be
{\em strictly complementary}. 
On the grounds of a strictly complementary
solution we can define the concept of {\em optimal partition}.
Following Jansen \cite{phd:Jansen}, we define the support set
of a vector $v \in \R^n$ as
\[
   \sigma(v) = \{ i : v_i > 0, \; i=1,\ldots,n \},
\]
and partition the set of indices $\{1,\ldots,n \}$ as
\[
   \mathcal{B} = \sigma(x^*), \quad \mathcal{M} = \sigma(s^*).
\]
This partition is well-defined in the sense that a 
strictly complementary solution satisfies both 
$\mathcal{B} \cap \mathcal{M} = \emptyset$ and 
$\mathcal{B} \cup \mathcal{M} = \{1,\ldots,n \}$. 
A proof of the latter result, also known as the Goldman-Tucker theorem, 
can be found in \cite{ipm:Wright97}.
The notions of strict complementarity and optimal partition are
recurrent motifs in the analysis of interior point methods.

In the common case of multiple solutions, an interior point method
algorithm terminates
at the analytic center of the optimal face rather than at a vertex; 
in some respects, through the concept of optimal partition, we can interpret
this situation as having determined the whole set of optimal solutions.
In contrast, the choice of the solution vertex provided by the simplex
method is arbitrary, and depends on factors like the pivoting rule.

Often having a basis solution that identifies a vertex is considered
to be an exact solution.
However, we should discuss what we mean by ``exact'' solution. In most
cases we do not need the additional precision of being on a vertex 
solution rather that in an arbitrarily small neighbourhood of it.
In this sense, integer programming represents a notable exception,
as the integer solutions are in general at the vertices of the
convex hull of feasible integer points.
The difference between having an optimal basis or an optimal partition
has important consequences on the use of the solution
for sensitivity analysis \cite{phd:Jansen,YildirimTodd01}.

Vavasis and Ye \cite{VavasisYe} studied the properties of the 
curvature of the central path, discovering that the central path
is characterised by $\bigO(n^2)$ curves of high degree and
segments where it is relatively straight.
Such curves appear in correspondence with changes in the optimal
partition.
Close to the end, when the optimal partition has been identified,
the central path becomes a straight line \cite{Megiddo}.
In this region, the algorithm displays the quadratic convergence 
property typical of Newton's method.

We now consider
the limit of $(P_\mu)$ for $\mu \to \infty$, and therefore
find the point from which the central path departs.
This corresponds to finding the point $\hat{x}$ 
that minimizes the barrier function, that is
\[
  \hat{x} = \arg \min_{x \in \mathcal{P}^0} \big(-\sum_{i=1}^n \ln x_i \big).
\]
The point $\hat{x}$ is the {\em analytic center} of the feasible polytope, 
and was first studied by Sonnevend \cite{Sonnevend86}.
Given the strict convexity of the barrier function, the concept 
of analytic center is well defined.
As the analytic center minimizes the barrier, it
is the point farthest away from the boundary.

However, there is a problem with defining the central path in terms
of analytic center: the central path is affected by the presence of 
redundant constraints. 
This happens because it is an exclusively analytic concept, which does
not exploit geometric considerations.

Such a drawback of the central path has been shown to 
have the potential for extreme
consequences by Deza \etal \cite{DezaNematollahiPeyghamiTerlaky},
who managed to replicate the behaviour of the simplex method
on the Klee-Minty cube within an interior point context. 
This was obtained by adding an exponential
number of redundant constraints parallel to the faces of the cube, so
that the central path gets heavily distorted and goes through
an arbitrarily small neighbourhood of all vertices of the cube.

Here we mention the fact that presolve
techniques are usually implemented to find and remove as many as
possible of these constraints, but while they are based on successful
heuristics, they are not optimal. In particular, they may find 
implied constraints hard to detect (see Cartis and Gould).

To overcome this disadvantage,
other types of centers (center of gravity, center of the ellipsoid of 
maximum volume that can be inscribed in $\mathcal{P}$, volumetric center) 
can be defined, but they usually are too demanding to compute 
\cite{Gonzaga92}. 

%
%
\subsection{Neighbourhoods of the central path}
\label{sec:Neighbourhoods}

As we have seen, following the central path is the recommended
way of traversing the interior of the feasible region towards
the optimal solution. Nevertheless, it should be clear that keeping the
iterates {\em exactly on} the central path is an unachievable aim.
Finding a point that solves the perturbed complementarity conditions 
(\ref{eq:PerturbedComplementarity}) for a specific $\mu$ 
is as difficult as solving the optimization problem itself.
%
Therefore, we never insist on this extremely restrictive requirement,
but we rather allow the iterates to be somewhere around the central path.
This leads to the introduction of the concept of
{\em neighbourhood} of the central path. 
We can define several neighbourhoods, characterised
by different properties.
Two neighbourhoods are often used in theoretical developments.

The first is based on the Euclidean norm, and it is often referred
to as the {\em tight neighbourhood}:
\[
\Nhood_2(\theta) = \{ w \in \mathcal{F}^0 :
                         \| XSe - \mu e \|_2 \le \theta\mu \},
\]
where $\theta \in (0,1)$.
This neighbourhood defines points which lie very close to the central path.
Search directions generated from points in this neighbourhood can be 
followed with a full step, and the barrier parameter can be decreased
by a small amount at each iteration (giving rise to the name
of {\em short-step algorithms} to the algorithms that are based on
this neighbourhood). 
The closeness to the central path that the tight neighbourhood
imposes and maintains produces the best convergence result
for linear programming: short-step algorithms converge in 
$\bigO(\sqrt{n}L)$ iterations \cite{KojimaMizunoYoshise89b,MonteiroAdler89a}.
However, since the reduction in the barrier parameter at each iteration 
is very small, the practical value of short-step algorithms is limited.

The other commonly used neighbourhood is based 
on the one-sided infinity norm, 
and it is often called the {\em wide neighbourhood}:
\[
\Nhood_{-\infty}(\gamma) = \{ w \in \mathcal{F}^0 :
                         x_is_i \ge \gamma\mu, \; i = 1, \ldots, n \},
\]
where $\gamma \in (0,1).$
Algorithms based on such a neighbourhood are allowed to generate
iterates that follow the central path more loosely. The iterates 
have more freedom of movement as they can get closer to the boundary
of the feasible set.
However, the Newton direction computed from points in the wide 
neighbourhood  has weaker properties, and a linesearch procedure is
needed to ensure that the positivity of the $(x,s)$ iterates is
preserved.
Algorithms based on the wide neighbourhood (usually called
{\em long-step algorithms}) are less conservative than their short-step
counterparts, and can decrease 
the barrier parameter more rapidly.
Efficient implementations of interior point methods are based
on some variation of a long-step algorithm.

In Section~\ref{sec:SymNeighbourhood} we will study a variation
of the $\Nhood_{-\infty}$ neighbourhood which better describes
the centrality requirements needed for a practical algorithm.

\ignore{
$N_2(\beta) \subseteq N_\infty(\beta) (= \| XSe - \mu e\|_\infty) \subseteq N_{-\infty}(\beta)$
}


%
% Section
%
\section{Path-following algorithms}
\label{sec:PathFollowingAlgorithms}

We now bring together the elements we presented above and describe
a complete path-following algorithm. We then discuss some
theoretical results for algorithms in this class.

Primal--dual path-following methods solve the perturbed \KKT
conditions (\ref{eq:KKT}) by asking the complementarity pairs to align 
to a specific barrier parameter $\mu > 0$,
\be  \label{eq:PerturbedComplementarity}
XSe = \mu e,
\ee
while enforcing $(x,s)>0$.
However, up to now, we have not defined how to choose the
barrier parameter $\mu$ and how to update it at each iteration.

Given a starting iterate $w^0$ such that $(x^0, s^0) > 0$, the value $\mu^0$ 
of the barrier parameter is given by
\[
   \mu^0 = \frac{(x^0)^T s^0}{n}.
\]
With the progress of iterations 
we would like the perturbed \KKT conditions (\ref{eq:PerturbedKKT}) 
to better and better approximate
the system (\ref{eq:KKT}) of optimality conditions for the original
problem.
Hence, at each iteration, $\mu$ is monotonically decreased by the quantity
$\sigma \in (0,1)$, called the {\em centering parameter} for reasons that
will become clear later on.
The choice of the centering parameter $\sigma$ 
is algorithm-dependent. We provide theoretical insights on some
possible choices in Section~\ref{sec:FeasibleMethods}.

\ignore{
In all predictor--corrector algorithms there is a crucial decision 
to be made at every iteration, namely the choice of the penalty 
parameter $\mu$ to be used in the correction.

The paper \cite{VillasBoasPerin} tries to answer this question. 
They build a polynomial function of $\mu$ and $\alpha$, and they 
use to determine what the optimal choices of these parameters are, 
under a suitably chosen measure.

By using this strategy they achieve a better iteration count on 
most of the problems in their experiment. This, however, is not 
supported by a corresponding reduction in computational time. 
The reason for this is that the postponing of the choice of $\mu$ 
requires the solution of additional systems. While it's true that 
the most expensive operation is the computation of the Cholesky 
factors, the actual cost of the backsolves is not negligible. 
In the results of this paper, the additional cost of the extra 
backsolves is bigger than the savings obtained by the decrease 
in number of iterations.
}

Path-following interior point methods seek a solution 
to the system of equations (\ref{eq:PerturbedKKT})
\be  \label{eq:KKTSystem}
F(w) = \left[
  \begin{array}{c}
    Ax-b \\
    A^Ty+s-c \\
    XSe - \sigma\mu e \\
  \end{array} \right] = 0,
\ee
which is nonlinear in the perturbed complementarity constraints.
We use Newton's method to linearise the system around the 
current point according to
\[
  \nabla F(w) \Delta w = -F(w),
\]
where $\nabla F(w)$ is the Jacobian of the function (\ref{eq:KKTSystem})
evaluated at the current primal--dual iterate $w$.
The linearisation produces the Newton system 
%
\be \label{eq:NewtonSystem}
\left[ \begin{array}{ccc}
    A & 0 & 0 \\ 0 & A^T & I \\ S & 0 & X
  \end{array} \right]
\left[ \begin{array}{c}
    \Delta x \\  \Delta y \\  \Delta s
  \end{array} \right] =
\left[ \begin{array}{c}
    b - Ax \\ c - A^Ty - s \\ -XSe + \sigma\mu e
   \end{array} \right] =
\left[ \begin{array}{c}
    \xi_b \\ \xi_c \\ \xi_\mu
   \end{array} \right],
\ee
%
which needs to be solved for a search direction
$\Delta w = (\Delta x, \Delta y, \Delta s)$,
with $\mu = x^Ts/n$, $\sigma \in (0,1)$.
We will discuss some ways of solving system (\ref{eq:NewtonSystem})
in Section~\ref{sec:SolvingNewtonSystem}.

The search direction $\Delta w$ thus computed is used to generate 
a new iterate
\[
  w^{k+1} = w^k + \alpha\Delta w,
\]
where $\alpha \in (0,1]$ is the feasible stepsize computed in
such a way that
\[
   x + \alpha \Delta x > 0, \quad s + \alpha \Delta s > 0.
\]

In Algorithm~\ref{alg:PrimalDual} we present the steps of a 
primal--dual path-following algorithm.

\begin{algorithm}[ḧt]
  \caption{Primal--dual path-following algorithm}
    \begin{algorithmic}[0]  \label{alg:PrimalDual}
      \REQUIRE An initial iterate $w^0$ such that $(x^0, s^0) > 0$;
      \smallskip
      \REPEAT
        \STATE Solve system (\ref{eq:NewtonSystem}) with a specified $\sigma$
	       for a search direction $\Delta w$.
        \smallskip
        \STATE Evaluate the maximum feasible stepsize $\alpha_k$ in 
	       direction $\Delta w$.
        \smallskip
        \STATE Update the iterate $w^{k+1} = w^k + \alpha_k\Delta w$.
        \smallskip
      \UNTIL Some termination criteria are met.
    \end{algorithmic}
\end{algorithm}

%
%
\subsection{Feasible methods}
\label{sec:FeasibleMethods}

A feasible algorithm is characterised by the requirement that
all primal and dual iterates always lie within the interior 
of the feasible region. For this reason, these algorithms 
need to start from a strictly feasible point $w^0 \in\mathcal{F}^0$.

In the feasible case, $\xi_b = \xi_c = 0$
in the right-hand side of system (\ref{eq:NewtonSystem}). 
Since
the search direction computed from (\ref{eq:NewtonSystem})
guarantees
\[
  A \Delta x = 0 \quad \text{and} \quad
  A^T \Delta y + \Delta s = 0,
\]
we can easily verify that feasibility is maintained 
throughout the algorithm: 
\[
  \begin{split}
  A (x + \Delta x) &= Ax + A\Delta x = b, \\
  A^T(y +\Delta y) + (s +\Delta s) &= (A^T y +s) + (A^T\Delta y +\Delta s) = c.
  \end{split}
\]

As far as the progress in optimization is concerned,
we can evaluate the complementarity gap that we would
obtain when taking a step of length $\alpha$ in the direction $\Delta w$
\[
   x(\alpha)^Ts(\alpha) = x^Ts + \alpha(s^T \Delta x + x^T \Delta s)
     + \alpha^2 \Delta x^T \Delta s = (1 - \alpha (1 - \sigma)) x^Ts,
\]
where we used the fact that
$s^T \Delta x + x^T \Delta s = -x^Ts + \sigma\mu$.
Now, dividing through by $n$, we obtain
\be  \label{eq:OptimalityProgress}
   \mu(\alpha) = x(\alpha)^Ts(\alpha)/n = (1 - \alpha (1 - \sigma)) \mu.
\ee

From (\ref{eq:OptimalityProgress}) we observe that the progress in
optimization depends on both $\alpha$ and $\sigma$.
For a fixed $\sigma$, the length of the step $\alpha$ taken in 
the search direction
$\Delta w$ computed from (\ref{eq:NewtonSystem})
measures the reduction in complementarity gap: 
the longer the step, the bigger the reduction. This motivates
the attempts to enlarge the stepsize by the use of corrector
techniques (see Sections~\ref{sec:MehrotraPC} and
\ref{sec:MultipleCC} and Chapter~\ref{ch:Correctors}).

The centering parameter $\sigma$ plays an important role as well.
We can see that the biggest reduction is obtained for $\sigma = 0$.
This does not come as a surprise, as the choice of $\sigma = 0$
corresponds to solving the \KKT conditions (\ref{eq:KKT}) which
describe the optimality conditions for the linear program
(\ref{eq:PrimalDualPair}). The choice of $\sigma = 1$, instead,
leaves the complementarity gap unchanged. While this does not
produce progress towards optimality, it tends to move the iterate
closer to the central path. A step taken in a direction computed
with $\sigma = 1$ is often called a {\em pure centering step}.
It is therefore essential to choose $\sigma$ appropriately, trying
to balance the often conflicting aims of optimality and centrality.

Kojima, Mizuno and Yoshise \cite{KojimaMizunoYoshise89} 
proposed a polynomial-time long-step algorithm 
that makes use of the wide $\Nhood_{-\infty}$ neighbourhood
to measure the distance of the iterates from the central path.
The update of the barrier parameter for this family of algorithms
happens for a constant 
\[
  \sigma \in [\sigma_{\min},\, \sigma_{\max}]
\]
independent of $n$. 
This is an aggressive update, and it implies that a full Newton
step is usually not feasible, so the stepsize needs to be damped.
Also, more than one iteration may have to be performed before
reducing the barrier parameter again.
This algorithm, as well as many similar variants, has
property of convergence in $\bigO(nL)$ iterations.

This result was then refined by the same group \cite{KojimaMizunoYoshise89b} 
and by Monteiro and Adler \cite{MonteiroAdler89a},
who both presented a primal--dual algorithm for linear programming 
based on the tight $\Nhood_2$ neighbourhood
with the property of convergence in $\bigO(\sqrt{n}L)$ iterations.
This is still the best complexity result for interior point methods
for linear programming.

In a short-step feasible method based on the $\Nhood_2$ neighbourhood
the barrier parameter is reduced by 
\be  \label{eq:ShortStepSigma}
   \sigma = 1 - \delta/\sqrt{n}
\ee
at each iteration, for some positive constant $\delta$, usually
very small (0.05 according to Gonzaga \cite{Gonzaga91a}).
As $\sigma$ is always very close to 1, a lot of emphasis is put 
on maintaining centrality rather than advancing towards optimality. 
%
The slight reduction of the barrier parameter at
each iteration guarantees that one iteration of Newton's
method can keep the point in the tight neighbourhood of the central path.
The choice of (\ref{eq:ShortStepSigma}) allows convergence
in $\bigO(\sqrt{n}L)$ iterations to be proved.
However, this is a worst-case analysis, and in practice the same would happen
even with a bigger update of the barrier parameter. This suggests that
studying ways of allowing a more substantial reduction of the barrier
parameter, at least in some iterations, would be worthwhile. 

One important result in this direction was obtained by 
Mizuno, Todd and Ye \cite{MizunoToddYe}, who introduced a short-step 
predictor--corrector method. Their strategy uses two nested neighbourhoods 
$\Nhood_2(\theta^2)$ and $\Nhood_2(\theta)$, $\theta \in (0,1)$, 
and exploits the
quadratic convergence property of Newton's method in such a tight
neighbourhood of the central path.
Their algorithm alternates between two search directions characterised by
different properties.
Starting from a point in the $\Nhood_2(\theta^2)$ neighbourhood,
by choosing $\sigma = 0$ in (\ref{eq:NewtonSystem}),
the predictor direction gains optimality, possibly at the expense of
worsening centrality, keeping the iterate in a larger neighbourhood
$\Nhood_2(\theta)$ of the central path. 
Then, a pure re-centering step is performed, by setting $\sigma = 1$,
leaving the duality gap unchanged but moving the iterate back into a 
tighter $\Nhood_2(\theta^2)$ neighbourhood. Hence, on every second step the 
algorithm produces a point in $\Nhood_2(\theta^2)$.

The Mizuno-Todd-Ye predictor--corrector algorithm \cite{MizunoToddYe},
achieves the $\bigO(\sqrt{n}L)$ convergence property
thanks to the optimizing predictor
direction which guarantees the same progress achievable by a short-step 
feasible method, with the only 
difference that the value of the barrier parameter is reduced over
two iterations.

An important contribution that this technique makes, is the idea 
of targeting optimality and centrality independently. 
The use of the very restrictive $\Nhood_2$ neighbourhood 
makes the Mizuno-Todd-Ye algorithm unattractive for practical applications,
but it provides a scheme 
upon which more computationally attractive methods can be constructed,
as we will discuss in Chapter~\ref{ch:PracticalIpm}.

%
%
\subsection{Infeasible methods}
\label{sec:InfeasibleMethods}

The results presented up to here concentrated on feasible methods. 
For these methods we assume that a strictly feasible starting point is
readily available.
However, finding a strictly feasible starting point is, 
in general, a nontrivial task.
Solving the feasibility problem is an optimization problem in its
own right, and is as difficult as solving the original problem
to optimality.
Moreover, the feasible region may have an empty interior,
in which case the theory developed above does not apply.
Allowing an infeasible starting point is particularly important
for the algorithms implemented in practical interior point solvers.
For these reasons, a need exists for developing techniques
that do not require feasibility of the 
starting iterate.

A way to find a strictly feasible starting point involves 
solving an artificial Phase~I subproblem by using 
the big-$M$ method. However, the performance is dependent on 
the choice of the values given to the weights, and the use
of very large values, while theoretically satisfying,
causes numerical instabilities \cite{Lustig91}.
This is worsened 
by the presence of dense columns that compromise the 
computational efficiency. 

A very different approach is based on the homogeneous 
self-dual formulation introduced by Ye, Todd and Mizuno
\cite{YeToddMizuno94}.
This and a simplified variant are presented in \cite[Chapter~9]{ipm:Wright97}.
The self-dual formulation wraps the optimization problem into one 
of slightly larger dimension, but for which a strictly feasible solution
is known from the start.
Therefore, once embedded in the homogeneous self-dual form,
the problem can be solved with a feasible algorithm.
This formulation also has the very
appealing property of being able to detect infeasibility
with accuracy.
The use of a self-dual formulation, however, comes with a price from a
computational viewpoint, particularly because of the need for
two extra backsolves at each iteration.

It is possible to develop an algorithm which only requires 
the $x$ and $s$ components to be strictly positive. 
This was initiated by Lustig \cite{Lustig91}, who proposed some
new feasibility restoration directions.
These were obtained as limiting directions as the big-$M$
weight tends to infinity, and were shown to be equivalent
to those obtained by an infeasible algorithm.
However, it was the work of Kojima, Megiddo and Mizuno 
\cite{KojimaMegiddoMizuno}
that provided full theoretical analysis of convergence of
an infeasible interior point method as well as
a stepsize rule that guarantees global convergence of the algorithm.

\fb{
Sure? Wright (page 109) says it was Lustig Marsten and Shanno.
}

In such 
an algorithm, all iterates are infeasible, but the limit points 
are feasible and optimal. This is obtained by using a 
neighbourhood that admits infeasible points:
\[
\Nhood_{-\infty}(\gamma,\beta) =\{ w :
           \|(\xi_b,\xi_c)\| \le \beta\mu \frac{\|(\xi_b^0,\xi_c^0)\|}{\mu_0}, 
	   \; (x,s)>0, \; x_is_i \ge \gamma\mu, \; i = 1, \ldots, n \},
\]
where $\gamma\in (0,1)$ and $\beta \ge 1$ are parameters, and 
$\xi_b^0,\,\xi_c^0$ are the primal and dual residuals, respectively, 
at the initial iterate $w^0$.

In the $\Nhood_{-\infty}(\gamma,\beta)$ neighbourhood
there is no strict feasibility requirement for 
the iterates; however, the residuals at each iteration must be 
bounded above by a multiple of the complementarity measure $\mu$. 
By reducing $\mu$ we can force the primal and dual residuals 
$\xi_b$ and $\xi_c$ to zero, thus approaching complementarity and 
feasibility at the same speed.

\ignore{
An algorithm is globally convergent if it is possible to choose
a strictly positive stepsize such that the complementarity gap
is reduced at each iteration. This property is very important, at it
guarantees the good behaviour of the algorithm for any given starting
point. 
However, for the global convergence property to hold, two 
safeguards need to be introduced.
The first requires that the reduction in infeasibility should be faster 
than in the complementarity gap. This ensures that the algorithm
does not get too close to a complementary point before feasibility
is restored.
The second safeguard forces $x_i s_i \ge \beta x^Ts$ for a chosen 
$\beta$, and requires that all iterates must stay in this neighbourhood.
\fb{
Check this Kojima-Megiddo-Mizuno stuff!
}
}

Letting 
$w(\alpha) = (x(\alpha),y(\alpha),s(\alpha)) = w + \alpha\Delta w$,
then we can show that
\[
  \xi_b(\alpha) = (1-\alpha) \xi_b \quad \text{and} \quad 
  \xi_c(\alpha) = (1-\alpha) \xi_c,
\]
so infeasibilities reduce linearly with $\alpha$, while for the 
complementarity gap
\[
  x(\alpha)^Ts(\alpha)=(1-\alpha(1 -\sigma))x^Ts +\alpha^2 \Delta x^T \Delta s,
\]
a reduction happens for a sufficiently small $\alpha$. 
When feasibility is restored, an infeasible algorithm becomes identical
to a feasible algorithm. 

A globally convergent infeasible interior point algorithm has
been implemented and tested by Lustig, Marsten and Shanno
\cite{LustigMarstenShanno94b}, who report positive results on
a set of feasible test problems.
The order of convergence for an infeasible algorithm was
established by Zhang \cite{Zhang94} to be $\bigO(n^2L)$.


%
% Section
%
\section{Symmetric neighbourhood}
\label{sec:SymNeighbourhood}

In Section~\ref{sec:Neighbourhoods} we discussed two neighbourhoods
employed in the theory of interior point methods, 
and illustrated their main features and drawbacks.
The $\Nhood_2$ neighbourhood follows the central path very tightly, 
and the short-step methods
based on it are extremely conservative and, ultimately, very slow.
The $\Nhood_{-\infty}$ provides a much better framework 
for practical algorithms, as it allows 
the barrier parameter to reduce quickly. However, as it does not actively
enforce an upper bound on the complementary products, it may allow the
iterates to produce very unbalanced products.

The issue of unbalanced complementary products is very important for
the practical success of an interior point code. 
We should stress how
the complementary pairs play a role in the Newton system, and how
their bad scaling causes a bad behaviour of Newton's method, which
produces unreliable directions.

Jansen \cite{phd:Jansen} considered the ratio 
\be  \label{eq:JansenRatio}
  \varrho(XSe) = \frac{\min(XSe)}{\max(XSe)}
\ee
between the smallest and the largest complementarity pair as an 
indication of the quality of a point.
The ratio (\ref{eq:JansenRatio}) is a measure between 0 and 1, and is 1
for a perfectly centered iterate.
Atkinson and Vaidya \cite{AtkinsonVaidya} noticed that 
the region in which Newton's method converges becomes smaller
as the ratio $\varrho(XSe)$ decreases. 

We argue that the quality of centrality 
(understood in a simplified way as complementarity)
for a practical implementation of an interior point algorithm
is {\it not} well characterised by either of two neighbourhoods 
$\Nhood_2$ or $\Nhood_{-\infty}$ commonly used in theoretical developments 
of interior point methods.

Practical experience with the primal--dual algorithm in \HOPDM \cite{HOPDM}
suggests that one of the features responsible 
for its efficiency is the way in which the quality of centrality 
is assessed. By ``centrality'' we understand here the spread 
of complementarity products $x_i s_i$, $i = 1,\dots,n$.
Large discrepancies within the complementarity 
pairs, and therefore bad centering, create problems for the search 
directions: an unsuccessful iteration is caused not only by small
complementarity products, but also by very large ones.
%
 This can be explained by the fact that
Newton's direction tries to compensate for very 
large products, as they provide the largest gain in complementarity 
gap when a full step is taken. However, the direction thus generated 
may not properly consider the presence of very small products, 
which then become blocking components when the stepsizes are computed.

The notion of spread in complementarity products
is not well characterised by either 
of the two neighbourhoods $\Nhood_2$ or $\Nhood_{-\infty}$ commonly used 
in theoretical developments of interior point methods.
To overcome this disadvantage, here we formalise a variation 
on the usual $\Nhood_{-\infty}(\gamma)$ neighbourhood, 
in which we introduce an upper bound on the complementarity pairs. 
We propose using a symmetric neighbourhood $\Nhood_s(\gamma)$,
in which complementarity pairs have to satisfy 
$\gamma \mu \leq x_i s_i \leq \gamma^{-1} \mu$, where $\gamma \in (0,1)$, 
for a strictly feasible iterate $w \in \mathcal{F}^0$.
This neighbourhood was implicitly used in \cite{Gondzio96}
to define an achievable target for multiple centrality correctors
(we refer the reader to Section~\ref{sec:MultipleCC}).

\fb{
Can I invent an example to show this?
}

We define the symmetric neighbourhood to be the set
\be  \label{eq:SymmetricNeighbourhood}
  \Nhood_s(\gamma)=\{ w \in \mathcal{F}^0: 
  \gamma\mu\le x_is_i \le \frac{1}{\gamma}\mu, \; i=1,\ldots,n\},
\ee
where 
$\mu = x^Ts/n$, and $\gamma \in (0,1)$.

While the $\Nhood_{-\infty}$ neighbourhood ensures that some 
products do not approach zero too early, it does not prevent products
from becoming too large with respect to the average.
In other words, it does not provide a complete 
picture of the centrality of the iterate. The symmetric 
neighbourhood $\Nhood_s$, on the other hand, promotes 
the decrease of complementarity pairs which are too large, thus taking 
better care of centrality.

An upper bound on the size of complementary products
is implicit in the $\Nhood_{-\infty}$ neighbourhood. To find it,
suppose that all but one of the complementarity products are at the lower bound
$\gamma\mu$:
\[
  n\mu = x_1s_1 + \sum_{i=2}^n x_is_i = x_1 s_1 + (n-1)\gamma\mu,
\]
from which it follows that in general
\be  \label{eq:UpperBoundN8hood}
  x_i s_i \le (n (1-\gamma) + \gamma) \mu, \quad i = 1, \ldots, n.
\ee
We note the dependence on the problem dimension in the definition of the
upper bound, hence its ineffectiveness for large-scale problems.

We now determine the value of $n$ for which the upper bound of
the symmetric neighbourhood is tighter than the implicit upper bound
(\ref{eq:UpperBoundN8hood}), that is
\[
  (n(1-\gamma) + \gamma)\mu > \frac{1}{\gamma}\mu.
\]
After some trivial manipulations we find that
the symmetric neighbourhood imposes a tighter upper bound
for
\[
  n > \frac{1+\gamma}{\gamma}.
\]
For a value of $\gamma = 0.1$, the bound is tighter whenever
$n > 11$.

%
%
\subsection{Theoretical analysis}

Many theoretical developments aim at lowering the upper bound on the number 
of steps needed for convergence. The results provided by such worst-case 
complexity analysis are informative but exceedingly pessimistic. 

Theoretical proofs of complexity generally follow a common scheme.
First they rely on a computable measure of the closeness to the central
path, accomplished by the concept of neighbourhood. Second,
they show that the direction computed by solving the Newton system
(\ref{eq:NewtonSystem}) can be followed with a strictly positive step
(and therefore some progress is made at every iteration) 
and generates an iterate 
that retains the property of being in some neighbourhood of the central 
path (possibly larger than the one before). Finally, they require
a decrease in the barrier parameter that allows derivation 
of a polynomial upper
bound on the number of iterations needed to reach the desired
level of accuracy.

We analyse a long-step feasible path-following 
algorithm based on the symmetric neighbourhood $\Nhood_s(\gamma)$, 
where the search direction $\Delta w$ 
is found by solving system (\ref{eq:NewtonSystem}) with 
$r=(0,\; 0,-XSe+\sigma\mu e)^T$, $\sigma\in(0,1)$, $\mu=x^Ts/n$.
The exposition closely follows the presentation of Wright
\cite[Chapter~5]{ipm:Wright97}. 

Our main results are presented in Theorem~\ref{th:SymNeighbourhood}
and Theorem~\ref{th:SymNeighbourhoodConvergence}.
However, we first need a technical result that corresponds to
Lemma~5.10 in \cite{ipm:Wright97}, the proof of which is unchanged by the use 
of $\Nhood_s$ rather than $\Nhood_{-\infty}$.
%
\begin{lemma} \label{Wright:5.10}
If $w \in \Nhood_s(\gamma)$, then\,
\(
  \|\Delta X\Delta Se\| \le 2^{-3/2}
                        \Big( 1+ \displaystyle{\frac{1}{\gamma}} \Big)n\mu.
\)
\end{lemma}

We now prove that it is possible to find a strictly positive stepsize 
$\alpha$ such that the new iterate 
$w(\alpha) = w + \alpha\Delta w$
does not leave the symmetric neighbourhood, and thus this 
neighbourhood is well defined. This result extends 
Theorem~5.11 in \cite{ipm:Wright97}.

\begin{theorem} \label{th:SymNeighbourhood}
If $w \in \Nhood_s(\gamma)$, then $w(\alpha) \in \Nhood_s(\gamma)$ for all
\[
  \alpha \in \left[0, \, 2^{3/2}\gamma\frac{1-\gamma}{1+\gamma}
                                      \frac{\sigma}{n} \right].
\]
\end{theorem}
%
\begin{proof}
Let us express the complementarity product in terms of the stepsize 
$\alpha$ along the direction $\Delta w$:
%
\begin{eqnarray} \label{eq:CompProdAlpha}
x_i(\alpha)s_i(\alpha)&=&(x_i+\alpha\Delta x_i)(s_i+\alpha\Delta s_i)\nonumber\\ 
&=& x_is_i+\alpha(x_i\Delta s_i +s_i\Delta x_i) +\alpha^2\Delta x_i\Delta s_i\\
&=& (1-\alpha)x_is_i + \alpha\sigma\mu + \alpha^2\Delta x_i\Delta s_i.\nonumber
\end{eqnarray}
%
We need to study what happens to this complementarity product 
with respect to both bounds of the symmetric neighbourhood.
Let us first consider the bound $x_is_i\le \frac{1}{\gamma}\mu$.
By Lemma~\ref{Wright:5.10}, equation (\ref{eq:CompProdAlpha}) implies
\[
x_i(\alpha)s_i(\alpha) \le (1-\alpha)\frac{1}{\gamma}\mu +\alpha\sigma\mu 
+ \alpha^2 2^{-3/2}\left( 1+ \frac{1}{\gamma} \right)n\mu.
\]
At the new point $w(\alpha)$, the duality gap
is $x(\alpha)^Ts(\alpha) = n\mu(\alpha)$.
The relation $x_i(\alpha)s_i(\alpha)\le \frac{1}{\gamma}\mu(\alpha)$ 
holds provided that
\[
(1-\alpha)\frac{1}{\gamma}\mu +\alpha\sigma\mu + \alpha^2 2^{-3/2}\left( 1+ \frac{1}{\gamma} \right)n\mu 
\le\frac{1}{\gamma}(1-\alpha+\alpha\sigma)\mu,
\]
from which we derive a first bound on the stepsize:
\[
\alpha \le 2^{3/2}\frac{1-\gamma}{1+\gamma}\frac{\sigma}{n} = \bar\alpha_1.
\]

Considering now the bound $x_is_i\ge \gamma\mu$ and using again
Lemma~\ref{Wright:5.10}, equation (\ref{eq:CompProdAlpha}) implies
\[
x_i(\alpha)s_i(\alpha) \ge (1-\alpha)\gamma\mu + \alpha\sigma\mu 
- \alpha^2 2^{-3/2}\left( 1+ \frac{1}{\gamma} \right)n\mu.
\]
Hence, $x_i(\alpha)s_i(\alpha)\ge \gamma\mu(\alpha)$ provided that
\[
(1-\alpha)\gamma\mu + \alpha\sigma\mu- \alpha^2 2^{-3/2}\left( 1+ \frac{1}{\gamma} \right)n\mu 
\ge\gamma(1-\alpha+\alpha\sigma)\mu,
\]
from which we derive a second bound on the stepsize:
\[
\alpha\le 2^{3/2}\gamma\frac{1-\gamma}{1+\gamma}\frac{\sigma}{n} =\bar\alpha_2.
\]

Therefore, for
\[
  \alpha \in [0, \, \min(\bar\alpha_1,\bar\alpha_2)] = [0, \, \bar\alpha_2],
\]
we satisfy both bounds of the symmetric neighbourhood.

To conclude our proof we need to show that the 
$w(\alpha)$ iterate is still strictly feasible.
Feasibility is trivially maintained, shown by the same argument as
in Section~\ref{sec:FeasibleMethods}.
For positivity, we have that
\[
  x_i(\alpha)s_i(\alpha) \ge \gamma \mu(\alpha) 
                         = \gamma(1 - \alpha(1-\sigma))\mu > 0,
\]
as $\gamma\in (0,1)$, $\sigma \in (0,1)$, and $\mu > 0$.
Hence $x(\alpha)>0$ and $s(\alpha)>0$, and $w(\alpha) \in \Nhood_s(\gamma)$.
\end{proof}

In the next theorem, we prove the global linear convergence
of the algorithm based on the symmetric neighbourhood.

\begin{theorem}  \label{th:SymNeighbourhoodConvergence}
Given $\gamma$ and $0 < \sigma_{\min} < \sigma_{\max} < 1$, 
there is a constant $\delta$ independent of $n$ such that
\be  \label{eq:MuConvergence}
  \mu^{k+1} \le \left( 1 -\frac{\delta}{n} \right) \mu^k,
            \qquad \forall k \ge 0.
\ee
\end{theorem}
%
\begin{proof}
Using (\ref{eq:OptimalityProgress}) and Theorem~\ref{th:SymNeighbourhood}, 
we have
\[
  \mu^{k+1} = \left[1 - \alpha(1-\sigma)\right]\mu^k
            \le \left[1 - \frac{2^{3/2}}{n}\gamma
                     \frac{1-\gamma}{1+\gamma}\sigma(1-\sigma) \right] \mu^k.
\]
The term $\sigma(1-\sigma)$ is concave and assumes strictly positive values 
in the interval $(0,\,1)$, with its minimum attained at one of the 
endpoints of the interval. Therefore, we prove our claim by setting
\[
  \delta = 2^{3/2}\gamma\frac{1-\gamma}{1+\gamma}
           \min \Big\{\sigma_{\min}(1-\sigma_{\min}),\,
                      \sigma_{\max}(1-\sigma_{\max}) \Big\}. \qedhere
\]
\end{proof}

It is interesting to note that the introduction of the upper bound 
on the complementarity pairs does not change the polynomial complexity 
result proved for the long-step variant in the 
$\Nhood_{-\infty}(\gamma)$ neighbourhood 
\cite[Theorem~5.12]{ipm:Wright97}. 
In fact, the following theorem holds.

\begin{theorem}
For a starting point $w^0 \in \Nhood_s(\gamma)$, $\gamma \in (0,\, 1)$,
such that $\mu^0 \le 1/\epsilon^\tau$,
where $\epsilon > 0$ is the convergence tolerance and $\tau > 0$,
there is an index $K = \bigO(n \ln \frac{1}{\epsilon})$ for which
\[
  \mu^k \le \epsilon
\]
for all iterations $k \ge K$.
\end{theorem}
%
\begin{proof}
This proof reworks Theorem~3.2 from \cite{ipm:Wright97} in our case.
Iterating from (\ref{eq:MuConvergence}) we obtain
\[
  \mu^k \le \left( 1 -\frac{\delta}{n} \right)^k \mu^0.
\]
We now take logarithms of both sides
\[
  \ln\mu^k \le k \ln\left( 1 -\frac{\delta}{n} \right) + \ln\mu^0
           \le k \ln\left( 1 -\frac{\delta}{n} \right) + 
               \tau \ln\frac{1}{\epsilon}
           \le - k \frac{\delta}{n} + \tau \ln\frac{1}{\epsilon},
\]
where the last inequality is derived from the fact that
$\ln(1 + \beta) \le \beta$ for $\beta > -1$.
The convergence tolerance is met when
\[
   - k \frac{\delta}{n} + \tau \ln\frac{1}{\epsilon} \le \ln \epsilon
       = -\ln \frac{1}{\epsilon},
\]
which holds for
\[
  k \ge \frac{1 + \tau}{\delta} n \ln \frac{1}{\epsilon}.
  \qedhere
\]
\end{proof}

Therefore, the additional upper bounds on the complementarity pairs
introduced with the symmetric neighbourhood do not produce any losses
in the theoretical results proved for the $\Nhood_{-\infty}$, but 
contribute to providing a better practical environment.
This understanding provides some additional 
insight into the desired characteristics of a well-behaved iterate.

The use of the symmetric neighbourhood will be one of the theoretical
motivations of this work. Through it, in Section~\ref{sec:MultipleCC}
we will put the work of \cite{Gondzio96} inside a more sound framework.
Then we will use it again in the presentation of the weighted corrector
directions strategy of Chapter~\ref{ch:Correctors}, and in the analysis of an 
original warm-start strategy for stochastic programming of 
Chapter~\ref{ch:Warmstart}.
